{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Challenge WS 2022/23\n",
    "\n",
    "#### Task:\n",
    "\n",
    "Your Task is to train a clickbait filter to classify clickbait articles by their headline. You freely decide how to prepare the data and which ML model to use for classification.\n",
    "\n",
    "The challenge is considered passed if your model performs better than our baseline (a simple classifier; F1 ~0.89). Report at least the F1 score of your classifier. Your model will be evaluated using a hold out dataset. Please prepare a script so your trained model can be evaluated with this dataset.\n",
    "\n",
    "#### Dataset:\n",
    "\n",
    "The data consists of two files, a text file with clickbait headlines and one with headlines from news sources. The hold out dataset is organized the same way."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission by :\n",
    "    Abhijit Ramsajivan Yadav (1619172)\n",
    "    Saurabh Mishra (1608460)\n",
    "    Sohail Ahmed Qadri (1620630)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Guys Try Tinder',\n",
       " 'Michael B. Jordan Got Laid The Fuck Out While Filming \"Creed\"',\n",
       " 'What\\'s The Most Fucked Up Thing You\\'ve Done On \"Rollercoaster Tycoon\"',\n",
       " 'How Far Would You Make It In The Hunger Games',\n",
       " \"If Matthew Gray Gubler's Tweets Were Motivational Posters\",\n",
       " \"Here's What Everyone Wore To The Glamour Women Of The Year Awards\",\n",
       " 'How Many Of These Black Sitcoms Have You Seen',\n",
       " '17 Reasons You Should Love Eddie Redmayne',\n",
       " \"Here's What Lady Gaga's Next Album Should Sound Like, According To Her Little Monsters\",\n",
       " 'Are These People Smiling At A Baby Or A Laptop']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('clickbait_yes') as f:\n",
    "    lines = [line.rstrip() for line in f]\n",
    "\n",
    "lines[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "df_data_yes = pd.read_csv(\"./clickbait_yes\", delimiter='\\n', header=None, names=[\"headline\"])\n",
    "df_data_no = pd.read_csv(\"./clickbait_no\", delimiter='\\n', header=None, names=[\"headline\"])\n",
    "df_label_yes = pd.DataFrame(np.ones((df_data_yes.shape[0])),columns=['label'])\n",
    "df_label_no = pd.DataFrame(np.zeros((df_data_no.shape[0])),columns=['label'])\n",
    "df_headline = pd.concat([df_data_yes, df_data_no], ignore_index=True)\n",
    "headline = df_headline.headline.values\n",
    "df_label = pd.concat([df_label_yes, df_label_no], ignore_index=True)\n",
    "label = df_label.label.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0 ...   522   159  1619]\n",
      " [    0     0     0 ...   294  4237  6085]\n",
      " [    0     0     0 ...     9 12394  6086]\n",
      " ...\n",
      " [    0     0     0 ...    30  1447   278]\n",
      " [    0     0     0 ...  1909     8  1895]\n",
      " [    0     0     0 ...     4  2923   307]]\n"
     ]
    }
   ],
   "source": [
    "#preprocess\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(headline)\n",
    "sequences = tokenizer.texts_to_sequences(headline)\n",
    "data = pad_sequences(sequences)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions?\n",
    "\n",
    "[kuglerk@uni-trier.de](mailto:kuglerk@uni-trier.de?subject=ML%20Challenge%20NLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, df_label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23040, 21)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "model = Sequential()\n",
    "vocab_size = 25000\n",
    "max_length = 21\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_length))\n",
    "model.add(LSTM(units=64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "720/720 [==============================] - 31s 41ms/step - loss: 0.1213 - accuracy: 0.9535 - val_loss: 0.0614 - val_accuracy: 0.9769\n",
      "Epoch 2/2\n",
      "720/720 [==============================] - 30s 42ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.0655 - val_accuracy: 0.9757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22015200b20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "model.fit(X_train, y_train, epochs=2, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0655 - accuracy: 0.9757\n",
      "Test accuracy: 0.9756944179534912\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "F1 score: 0.975593\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "# predict crisp classes for test set\n",
    "yhat_classes = model.predict(X_test, verbose=0)\n",
    "yhat_classes = np.around(yhat_classes)\n",
    "print(yhat_classes)\n",
    "#f1 calculation\n",
    "f1 = f1_score(y_test, yhat_classes)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation data \n",
    "df_eval = pd.read_csv(\"./clickbait_hold_X.csv\", header=None, names=[\"headline\"])\n",
    "eval = df_eval.headline.values\n",
    "tokenizer.fit_on_texts(eval)\n",
    "sequences = tokenizer.texts_to_sequences(eval)\n",
    "eval = pad_sequences(sequences)\n",
    "#predict the values\n",
    "yhat_classes = model.predict(eval, verbose=0)\n",
    "yhat_classes = np.around(yhat_classes)\n",
    "yhat_classes = yhat_classes.flatten()\n",
    "\n",
    "#export the file\n",
    "\n",
    "df_eval = pd.DataFrame(yhat_classes.astype(int))\n",
    "\n",
    "df_eval.to_csv(\"precited_labels for new data.text\",index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "198dc38c81252feb4faa0d475279f5f6c993dd4570bd3709069413259282040c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
